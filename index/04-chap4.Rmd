```{r, include = F}
library(tidyverse)
library(patchwork)
library(sf)
library(USAboundaries)
library(latex2exp)
library(scales)
res <- readRDS("data/results/final_results.rds")
res_long <- readRDS("data/results/final_results_long.rds")
dat <- read_csv("data/subsets/dat_small.csv") %>%
  filter(province %in% unique(res_long$province))

means <- res_long %>%
  filter(estimator == "dirmean") %>%
  rename(mean = estimate) %>%
  dplyr::select(subsection, response, mean)
res_long <- res_long %>%
  full_join(means, by = c("subsection" = "subsection",
                          "response" = "response"))
res_long <- res_long %>%
  mutate(se = mean * cov)

# for six cov maps:
subsections <- st_read("../data/SA_eco_subsection/SA_eco_subsection.shp", quiet = TRUE)

interior_west <- c("AZ", "CO", "ID", "MT", "NV", "NM", "UT", "WY")

int_west_sf <- us_boundaries(type = "state",
                         states = interior_west)

modeled_subsections <- st_intersection(int_west_sf, subsections) %>%
  dplyr::select(PROVINC, SECTION, SUBSECT, geometry)

res_sf <- res %>%
  full_join(modeled_subsections, by = c("subsection" = "SUBSECT")) %>%
  distinct()

res_long_sf <- res_long %>%
  full_join(modeled_subsections, by = c("subsection" = "SUBSECT")) %>%
  distinct()

res_long_sf_na <- res_long_sf %>%
  filter(is.na(estimator))

res_long_sf_na <- bind_rows(
  res_long_sf_na, res_long_sf_na, res_long_sf_na,
  res_long_sf_na, res_long_sf_na, res_long_sf_na
) 

res_long_sf_na$estimator <- c(
  rep("dirmean", 61), rep("dirps", 61), rep("freq_unit", 61),
  rep("freq_area", 61), rep("hb_unit", 61), rep("hb_area", 61)
)
```

# Results {#results}

This chapter addresses the performance of the six estimators in this thesis: the sample mean, the post-stratified estimator, the unit-level EBLUP, the area-level EBLUP, the unit-level hierarchical Bayesian estimator, and the area-level hierarchical Bayesian estimator. 

I used the R statistical software to compute the results [@r-software]. The sample mean was computed using the `sae` [@sae-package]. The post-stratified estimates were computed using `mase` [@mase]. The frequentist EBLUP estimates were computed using `sae` [@sae-package]. The hierarchical Bayesian estimates were computed using `hbsae` [@hbsae-package]. The results were tidied, processed, and visualized using many `tidyverse` packages [@tidyverse]. The data spans the entire Interior West; however, I was forced to exclude a few eco-provinces: namely, two eco-provinces with a very small number of eco-subsections that caused errors in producing the unit-level hierarchical Bayesian estimates. I also had to exclude estimates in a few eco-subsections with either no or very close to no sampled areas with non-zero values for the variables of interest: that is, areas which are in extremely non-forested areas. While this is disappointing, I was still able to fit these estimators to the great majority of the data. 

This thesis uses all six of these estimators to produce estimates for basal area ($\text{ft}^2$), tree count per acre, above-ground biomass (lbs), and net volume ($\text{ft}^3$). The EBLUP and hierarchical Bayesian estimators use one explanatory variable--total canopy cover--to produce estimates. The estimation occurs at the eco-subsection level, and thus I have produced 10,176 estimates (six estimators, four response variables, and 424 eco-subsections). 

This thesis is generally concerned with producing estimates that have both low variance and low bias. This chapter primarily aims to answer questions regarding these two quantities. In order to do so, I will summarize the findings both globally and by briefly examining a subset of our results in the Northern Rocky Forest. This subset examination allows for deeply digging into results without much aggregation or incomprehensible plots due to the large amount of results in this thesis. The Northern Rocky Forest is a beneficial eco-province to explore as it is more heavily forested than much of the Interior West, which allows for a better sense of how these estimators may perform in other heavily forested regions such as Alaska and the Pacific Northwest. I explore both metrics and visualizations of variance and bias across the Interior West in order to deeply understand the performance of our estimators. This thesis is, in many ways, a study navigating the bias-variance trade-off in depth in a real world setting. While quantifying variance of estimates is a generally straightforward task, producing an accurate depiction of bias is extremely difficult without knowing population parameters. 

## The Big Picture

Now I will investigate the performance of the six estimators used in this thesis. In order to explore variance, the primary metric used in this thesis is the coefficient of variation ($CV$). This metric, for each estimator, is defined as the standard deviation of the estimate divided by the sample mean in that small area ($\hat \mu_{y_j}^{HT}$). This allows for normalization of variation across different response variables and areas that are more or less forested. The coefficient of variation is expressed as follows:
\begin{align}
CV_{y_j} = \frac{\hat\sigma_{y_j}}{\hat\mu_{y_j}^{HT}}
\end{align}
It is notable that when the mean of the variable of interest is small, the coefficient of variation sometimes produces strangely large values for estimators that borrow strength. This phenomenon can generally be thought of as having more to do with intrinsic (and often very good) qualities of the estimator rather than correlation with "poor performance" of the estimator when the sample mean is small. Notably, estimators which borrow strength to a large degree in situations in which the sample mean is low and the areas from which strength is borrowed have significantly higher values will have higher variance due to this heterogeneity. I will explore this idea in depth further on in this chapter. 
\clearpage
In order to visualize the coefficients of variation in an appealing way, I have filtered out all observations greater than one in Figure \@ref(fig:cov-violin) below.   

```{r cov-violin, fig.align="center", out.width='100%', echo = FALSE, warning = F, message = F, fig.scap="Distribution of the coefficient of variation of each estimator", fig.cap = "Distribution of the coefficient of variation of each estimator. The black dot in each violin segment represents the median coefficient of variation value. The width of the violin segments corresponds to the density of points in the given value range. Values greater than one are truncated in plot but still considered in median calculation."}
med <- res_long %>%
  group_by(estimator) %>%
  summarize(median_cov = median(cov))

res_long %>%
  mutate(estimator = fct_reorder(.f = estimator, .x = cov, .fun = median, .desc = TRUE)) %>%
  ggplot(mapping = aes(x = estimator,
                       y = cov,
                       fill = estimator)) +
  geom_violin(alpha = 0.5) +
  geom_point(data = med, mapping = aes(x = estimator, y = median_cov)) +
  ylim(0,1) +
  theme_bw() +
  scale_fill_manual(values = c("#A9A9A9", "#334F44", "#80BCA2",
                               "#BF4C27", "#E7AB26",  "steelblue"),
                    labels = c("Sample Mean", "Post-Stratification", "Unit HB",
                               "Unit EBLUP", "Area EBLUP", "Area HB")) +
  scale_x_discrete(labels = c("Sample Mean", "Post-Stratification", "Unit HB",
                               "Unit EBLUP", "Area EBLUP", "Area HB")) +
  theme(legend.position = "bottom") +
  labs(title = "Coefficient of Variation of Each Estimator",
       x = "Estimator",
       y = "Coefficient of Variation",
       fill = "Estimator")
```
Figure \@ref(fig:cov-violin) shows the coefficient of variation for each estimator. One can see a slight reduction in the coefficient of variation when moving from the sample mean to post-stratification, and a decently large reduction in variation when adding auxiliary data with either EBLUP estimator. One also can see that the unit-level hierarchical Bayesian estimator performs quite similarly to the unit-level EBLUP. This makes sense, as at the unit-level there is so much data that it significantly outweighs the contribution of any priors. Finally, one can see a huge reduction in the coefficient of variation compared to all other estimators when the area-level hierarchical Bayesian estimator is fit. The median coefficient of variation for this area-level hierarchical Bayesian estimator (`r round(med$median_cov[5], 3)`) is less than half of the next best performing median coefficient of variation from the area-level EBLUP (`r round(med$median_cov[3], 3)`). Table \@ref(fig:quantile-table) examines the quantiles of these estimators' coefficients of variation and shows the superiority of the area-level hierarchical Bayesian estimator while also demonstrating the metric's tendency to have some extremely large values.
```{r quantile-table, echo = F}
quantiledf <- bind_rows(
  quantile(res$cov_dirmean),
  quantile(res$cov_dirps),
  quantile(res$cov_freq_area),
  quantile(res$cov_freq_unit),
  quantile(res$cov_hb_area),
  quantile(res$cov_hb_unit)
  ) %>%
  mutate(Estimator = c("Sample Mean", "Post-Stratification", "Area EBLUP",
                       "Unit EBLUP", "Area HB", "Unit HB")) %>%
  relocate(Estimator)

knitr::kable(
  quantiledf,
  digits = 3,
  caption = "Quantiles of Each Estimator's Coefficient of Variation",
  caption.short = "Coefficient of Variation Quantiles",
  longtable = TRUE,
  booktabs = TRUE
)
```

While Figure \@ref(fig:cov-violin) and Table \@ref(tab:quantile-table) give a good sense of the distribution, it is important to acknowledge that some values were truncated in Figure \@ref(fig:cov-violin) and further investigate why the coefficient of variation tends to become very large in some cases. By examining the distribution and performance of the coefficients of variation by truncating the tails in Figure \@ref(fig:cov-violin), insight can be gained that would be much harder to see when including the tails. Now, let's look more in depth at the tails of these distributions. Three estimators had coefficients of variation that exceeded one. Table \@ref(tab:over-one) shows the count and proportion of each.
```{r over-one, echo = FALSE, warning = F, message = F}
over_one <- res_long %>%
  filter(cov > 1) %>%
  group_by(estimator) %>%
  summarize(Count = n(),
            Proportion = Count / (length(res_long$response) / length(unique(res_long$estimator)))) %>%
  rename(Estimator = estimator) %>%
  mutate(Estimator = case_when(Estimator == "freq_unit" ~ "Unit EBLUP",
                               Estimator == "hb_area" ~ "Area HB",
                               Estimator == "hb_unit" ~ "Unit HB",
                               Estimator == "dirmean" ~ "Sample Mean")) %>%
  bind_rows(data.frame(Estimator = c("Post-Stratification", "Area EBLUP"),
                       Count = c(0,0),
                       Proportion = c(0.000, 0.000))) %>%
  arrange(Count)
# Fix R's rounding error (accidentally grabs 3 observations that are 1.00000 and says they are > 1)
over_one[3,2] <- 0
over_one[3,3] <- 0.000

knitr::kable(
  over_one,
  digits = 3,
  caption = "Coefficient of Variation Estimates Greater than One",
  longtable = TRUE,
  booktabs = TRUE
)
```
There are three estimators with at least one coefficient of variation greater than one. Both the frequentist and hierarchical Bayesian unit-level estimators have many values greater than one, and the area-level hierarchical Bayesian has some as well. To understand why these particular estimators have many estimates greater than one, I will explore the small areas which have these coefficient of variation values. To do so, I will examine the mean response value for estimates where the coefficient of variation is greater than one and when it is less than one in \@ref(tab:covg1l1). 
\clearpage
```{r covg1l1, message = F, warning = F, echo = F}
cov_g_1 <- res_long %>%
  mutate(`CV > 1` = cov > 1) %>%
  group_by(response, `CV > 1`) %>%
  summarize(mean = mean(estimate)) %>%
  pivot_wider(values_from = mean, names_from = `CV > 1`) %>%
  rename(l1 = `FALSE`,
         `g1` = `TRUE`)
names(cov_g_1) <- c("Response", "Mean Estimate (CV < 1)", "Mean Estimate (CV > 1)")

knitr::kable(
  cov_g_1,
  digits = 3,
  caption = "Mean Estimates for Coefficent of Variation Greater than and Less than One",
  longtable = TRUE,
  booktabs = TRUE
)
```
From this table one is able to confirm that high coefficients of variation occur more often in areas with lower values for the response variable. It now becomes apparent why some estimators have many coefficients of variation greater than one and others have none or very few. The three estimators which have coefficients of variation greater than one all will borrow a great deal of strength from outside eco-subsections when those outside eco-subections have a much higher response variable value than the eco-subsection of interest. In other words, with these three estimators, eco-subsections with lower response variable sample means will produce larger estimates. These larger estimates require a larger variance, as it is unclear whether the sample is non-representative (too low) in the given eco-subsection or if this eco-subsection truly has a low value for its response variable(s). However, when selecting methods of estimation which borrow strength, this is a beneficial property. In fact, estimators which do not borrow strength in these situations and have small coefficients of variation could be producing under-estimates with an artificial amount of precision. Figure \@ref(fig:cv-map) visualizes this phenomenon by examining the coefficient of variation of each estimator across the Interior West.
\clearpage
```{r cv-map, warning = F, message = F, echo = F, fig.align="center", fig.cap = "Average log coefficient of variation of each estimator in each eco-subsection plotted onto a map of the Interior West. The average is taken over the four response variables. The natural log is used to perserve a reasonable color scale. Gray areas represent areas where models were not fit.", fig.scap = "Coefficient of variation map"}
bind_rows(res_long_sf, res_long_sf_na) %>%
  filter(!is.na(estimator)) %>%
  mutate(estimator = case_when(
    estimator == "dirmean" ~ "Sample Mean",
    estimator == "dirps" ~ "Post-Stratification",
    estimator == "freq_area" ~ "Area EBLUP",
    estimator == "freq_unit" ~ "Unit EBLUP",
    estimator == "hb_area" ~ "Area HB",
    estimator == "hb_unit" ~ "Unit HB"
  )) %>%
  mutate(estimator = factor(estimator, levels = c("Sample Mean", "Post-Stratification",
                                                  "Area EBLUP", "Unit EBLUP",
                                                  "Area HB", "Unit HB"))) %>%
  ggplot() +
  geom_sf(mapping = aes(fill = log(cov),
                        geometry = geometry),
          color = NA) +
  theme_void() +
  facet_wrap( ~ estimator, ncol = 3, dir = "v") +
  scale_fill_gradient2(low = "#334F44",
                      mid = "white",
                      high = "#BF4C27",
                      na.value = "grey",
                      midpoint = 0) +
  theme(legend.position = "bottom") +
  guides(fill = guide_colorbar(title.position = "top", title.hjust = 0.5)) +
  labs(fill = "log(CV)")
```
The three estimators which have coefficient of variation values higher than one generally produce these values in heavily deserted areas in the southern parts of the Interior West and some deserts in the north parts of Nevada. It makes sense that these areas may truly have low values for the response variables given that the post-stratified estimator is doing its job correctly and the population totals for forested and non-forested areas are correct. On the other hand, it may be reasonable to use a higher variance estimate in these cases and borrow strength from surrounding areas. While it is difficult to say which approach to handling these situations provides a better estimate, Figure \@ref(fig:cv-map) highlights distinct ways in which the hierarchical Bayesian estimators (and the unit-level EBLUP) perform differently than the direct estimators and area-level EBLUP. 
\clearpage

## Zooming In: The Northern Rocky Forest

In order to take a closer look at *how* borrowing of strength differs between the area-level hierarchical Bayesian estimator and the area-level EBLUP estimator, I chose to zoom in to basal area in the Northern Rocky Forest. Figure \@ref(fig:m333-basal) displays the post-stratified, area-level EBLUP, and area-level hierarchical Bayesian estimates of basal area in the Northern Rocky Forest. 
```{r m333-basal, fig.align="center", out.width='100%', echo = FALSE, warning = F, message = F, fig.cap = "The post-stratified estimator, frequentist area-level estimator, and the hierarchical Bayesian area-level estimator predicting basal area in the Northern Rocky Forest. The error bars depict two standard errors above and below the estimate of the response variable.", fig.scap = "Post-stratified, area-level EBLUP, and area-level HB estimates in M333"}
res_long %>%
  filter(province == "M333",
         response == "BALIVE_TPA") %>%
  mutate(subsection = str_sub(subsection, 5),
         subsection = fct_reorder(subsection, estimate)) %>%
  filter(estimator %in% c("dirps", "hb_area", "freq_area")) %>%
  mutate(estimator = fct_relevel(.f = estimator, levels = c("freq_area", "dirps", "hb_area"))) %>%
  ggplot(mapping = aes(x = subsection,
                       y = estimate,
                       color = estimator)) +
  geom_errorbar(aes(ymin = estimate - 2*se,
                    ymax = estimate + 2*se),
                position = position_dodge(width = 0.7),
                width = 0.7) +
  geom_point(position = position_dodge(width = 0.7),
             size = 0.7) +
  scale_color_manual(values = c("#E7AB26", "#334F44", "steelblue"),
                     labels = c("Area EBLUP", "Post-Stratification", "Area HB")) +
  theme_bw() +
  theme(legend.position = "bottom") +
  labs(x = "Eco-subsection",
       y = TeX("Basal Area Estimate ($ft^2$)"),
       title = "Post-Stratified, Area-Level EBLUP, and Area-Level Hierarchical\nBayesian Estimates of Basal Area in the Northern Rocky Forest",
       color = "")
```
Immediately, when examining basal area in the Northern Rocky Forest, one can see the behavior of the hierarchical Bayesian area-level estimator "pulling up" lower valued eco-subsections compared to their post-stratified estimate. One can also observe that the eco-subsections with high response variable values will get "pulled down". However, the coefficient of variation does not increase significantly here, as the sample mean is still relatively high. The pulling up and down of estimates is a trait expected of these hierarchical Bayesian models, and it is the realization of "borrowing strength" or "pooling information" [@statrethinking]. 

Figure \@ref(fig:m333-basal) also displays the frequentist area-level estimator taking a different approach to making these estimates. Overall, the frequentist area-level estimator performs much more similarly to the post-stratified estimator, a trait that may or may not be appealing based on the confidence one has in the sampling process. However, it is important to note that the frequentist area-level estimator is still borrowing strength; it just appears that it will often borrow less strength than the hierarchical Bayesian area-level estimator. This is expected. Recall Equation \@ref(eq:eblup-area-weight) and note that when a large proportion of the total variation is between-area variation, the area-level EBLUP will rely heavily on the post-stratified estimate. Thus, in eco-subsections with low within-area variation, the area-level EBLUP will produce an estimate very similar to the post-stratified estimate. It is important to recall that much of the data contains many observations which equal zero (Figure \@ref(fig:hists) and Table \@ref(tab:var-tab)). So, in eco-subsections with a low number of sampled plots and a high proportion of sampled plots with response values equal to zero, artificially low variance may occur. The hierarchical Bayesian estimators have the unique property of considering the uncertainty in the variance estimate when producing estimates rather than relying on just a point value. 

## Stepping Back

When vision is narrowed to the Northern Rocky Forest, it does appear that the area-level hierarchical Bayesian estimator clearly outperforms the analogous frequentist estimator in all dimensions. However, I will now return to the Interior West in order to understand trends of estimator performance over space. To do this, I examine the eco-subsections in which the area-level hierarchical Bayesian estimator has lower variance than the post-stratified estimator and the area-level EBLUP in Figure \@ref(fig:boolmap1).
\clearpage

```{r boolmap1, warning = F, message = F, echo = F, fig.align="center", fig.cap = "The area-level hierarchical Bayesian estimator's coefficient of variation compared with the coefficient of variation for the post-stratified estimator (left) and area-level EBLUP (right). These are the average coefficient of variation across the four response variables studied. Eco-subsections in seafoam indicate areas in which the coefficient of variation is lower for the area-level hierarchical Bayesian estimator. Red areas indicate that the coefficient of variation of the hierarchical Bayesian estimator is greater than the estimator to which it is compared. Gray areas indicate areas in which we these estimators were not fit.", fig.scap = "Area-level coefficient of variation comparison across the Interior West"}
comparison_df <- res %>%
  group_by(subsection) %>%
  summarize(cov_hb_area = mean(cov_hb_area),
            cov_dirps = mean(cov_dirps),
            cov_hb_unit = mean(cov_hb_unit),
            cov_freq_area = mean(cov_freq_area),
            cov_freq_unit = mean(cov_freq_unit)) %>%
  mutate(hba_ps = cov_hb_area < cov_dirps,
         hba_fra = cov_hb_area < cov_freq_area,
         hbu_ps = cov_hb_unit < cov_dirps,
         hbu_fru = cov_hb_unit < cov_freq_unit) 

comparison_geometry <- res_sf %>%
  filter(response %in% c("BIOLIVE_TPA", NA)) %>% #get down to one response variable
  select(subsection, geometry) %>%
  full_join(comparison_df)

p1 <- comparison_geometry %>%
  ggplot(mapping = aes(fill = hba_ps,
                       geometry = geometry)) +
  geom_sf(color = "grey30") +
  scale_fill_manual(values = c("#BF4C27", "#80BCA2"), na.value = "grey") +
  theme_void() +
  labs(title = "Area HB CV < Post-Strat CV",
       fill = "") +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = 0.5)) 

p2 <- comparison_geometry %>%
  ggplot(mapping = aes(fill = hba_fra,
                       geometry = geometry)) +
  geom_sf(color = "grey30") +
  scale_fill_manual(values = c("#BF4C27", "#80BCA2"), na.value = "grey") +
  theme_void() +
  labs(title = "Area HB CV < Area EBLUP CV", fill = "") +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = 0.5)) 

(p1 + p2) + plot_layout(guides = 'collect') & theme(legend.position = "bottom")
```
Generally, one is able to see the trend in Figure \@ref(fig:cv-map) in which the area-level hierarchical Bayesian estimator produces estimates with higher variance in heavily deserted areas such as the southern parts of the Interior West and deserts in parts of Nevada. The areas in which the area-level hierarchical Bayesian estimator has more variation than the post-stratified estimator and the area-level EBLUP are clearly non-randomly distributed across the Interior West. This gives a great insight as to when one may want to use this hierarchical Bayesian estimator and further supports the idea that the area-level hierarchical Bayesian estimator has a high coefficient of variation in non-forested areas. These estimates are of the average coefficient of variation across our four response variables for each eco-subsection, and notably in 83.5% and 82.5% of these areas there is a decrease in the average coefficient of variation from the area-level hierarchical Bayesian estimator to the post-stratified estimator and the area-level EBLUP, respectively. 

I have largely discussed the variance of these estimators thus far, as the true bias of an estimator cannot be known without knowing the population parameters $\mu_{y_j}$ in each eco-subsection. However, in an attempt to quantify the magnitude of difference between two estimators, I introduce percent relative difference, which is defined below:
\begin{align*}
PRD(\hat\mu_1,~ \hat\mu_2) = \frac{\hat \mu_1 - \hat\mu_2}{\hat\mu_2} \cdot 100
\end{align*}
While one could explore percent relative difference among all combinations of estimators, the Forest Inventory and Analysis Program's go-to estimator is post-stratification. So I will compare the remaining five estimators to post-stratification. Additionally, post-stratification, as discussed in Chapter \@ref(methods), is an unbiased estimator given assumptions about the auxiliary data. Thus, I will rely on it for some proxy of truth. However, it is important to realize that this proxy is quite weak. Table \@ref(tab:prd-tab) display the quantiles of percent relative difference to post-stratification. 
```{r prd-tab, echo = F, warning = F, message = F}
knitr::kable(
  bind_rows(
    quantile((res$est_dirmean - res$est_dirps) / (res$est_dirps)) * 100,
    quantile((res$est_hb_unit - res$est_dirps) / (res$est_dirps)) * 100,
    quantile((res$est_hb_area - res$est_dirps) / (res$est_dirps)) * 100,
    quantile((res$est_freq_unit - res$est_dirps) / (res$est_dirps)) * 100,
    quantile((res$est_freq_area - res$est_dirps) / (res$est_dirps)) * 100
  ) %>%
    mutate(Estimator = c("Sample Mean", "Unit HB", "Area HB", "Unit EBLUP", "Area EBLUP")) %>%
    relocate(Estimator),
  digits = 3,
  caption = "Quantiles of Percent Relative Difference to the Post-Stratified Estimator",
  longtable = TRUE,
  booktabs = TRUE)
```
These quantiles continue to enforce the idea that the area-level EBLUP generally performs very similarly to the post-stratified estimator (albeit with lower variance). Notably, though, the percent relative difference between the area-level hierarchical Bayesian estimator and the post-stratified estimator is small compared to both unit-level models. The median values in Table \@ref(tab:prd-tab) can be thought of as some sort of proxy for each estimator's bias, but this is a difficult equivalency to make when the parameter values are not available. While this proxy for bias may be weak, it is reassuring that for the area-level hierarchical Bayesian estimator, the median (50% quantile) percent relative difference is somewhat low compared to other common estimators. 

Another aspect of the results in this thesis that percent relative difference allows one to investigate is the performance of an estimator which I have hardly addressed so far: the hierarchical Bayesian unit-level model. This thesis claims to be a hierarchical Bayesian approach to small area estimation, yet the performance of one of the hierarchical Bayesian estimators has yet to be discussed in depth in this chapter. This is because the area-level hierarchical Bayesian estimator outperforms it by a huge margin in terms of variance. However, the case of the unit-level hierarchical Bayesian estimator is interesting in itself, even if it does not increase precision of estimates. To understand its performance, Table \@ref(tab:prd-unit) examines its percent relative difference to the unit-level EBLUP estimator.
```{r prd-unit, echo = F, warning = F, message = F}
knitr::kable(
  bind_rows(
    quantile((res$est_hb_unit - res$est_freq_unit) / (res$est_freq_unit)) * 100
  ) %>%
    mutate(Estimator = c("Unit HB")) %>%
    relocate(Estimator),
  digits = 3,
  caption = "Quantiles of Percent Relative Difference to the Unit-level EBLUP",
  longtable = TRUE,
  booktabs = TRUE)
```
One can immediately see that the unit-level hierarchical Bayesian estimator is extremely similar to the unit-level EBLUP. That is, many of their estimates are within just a few percent difference compared to the unit-level EBLUP. This is because the likelihood outweighs any prior information given to this model to a large degree. At the unit level, there are so many observations that any reasonable prior has a negligible effect on the estimator's results. This illustrates the idea that under "flat" or "uninformative" priors, the hierarchical Bayesian estimates will converge to the analogous EBLUP estimator's estimates. Also, recall that not only should the estimates converge to the same point, but the variance should, as well. I illustrate this in Figure \@ref(fig:cov-violin) and in Figure \@ref(fig:boolmap2) below.
\clearpage
```{r boolmap2, warning = F, message = F, echo = F, fig.align="center", fig.cap = "The unit-level hierarchical Bayesian estimator's coefficient of variation compared with the coefficient of variation for the post-stratified estimator (left) and unit-level EBLUP (right). These are the average coefficient of variation across the four response variables studied. Eco-subsections in seafoam indicate areas in which the coefficient of variation is lower for the unit-level hierarchical Bayesian estimator. Red areas indicate that the coefficient of variation of the hierarchical Bayesian estimator is greater than the estimator to which it is compared. Gray areas indicate areas in which we these estimators were not fit.", fig.scap = "Unit-level coefficient of variation comparison across the Interior West"}
p3 <- comparison_geometry %>%
  ggplot(mapping = aes(fill = hbu_ps,
                       geometry = geometry)) +
  geom_sf(color = "grey30") +
  scale_fill_manual(values = c("#BF4C27", "#80BCA2"), na.value = "grey") +
  theme_void() +
  labs(title = "Unit HB CV < Post-Strat CV", fill = "") +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = 0.5)) 

p4 <- comparison_geometry %>%
  ggplot(mapping = aes(fill = hbu_fru,
                       geometry = geometry)) +
  geom_sf(color = "grey30") +
  scale_fill_manual(values = c("#BF4C27", "#80BCA2"), na.value = "grey") +
  theme_void() +
  labs(title = "Unit HB CV < Unit EBLUP CV", fill = "") +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = 0.5)) 
(p3 + p4) + plot_layout(guides = 'collect') & theme(legend.position = "bottom")
```
The distribution of areas in which the hierarchical Bayesian unit-level estimator has lower variance than the unit-level EBLUP appears to be very random. Just under 46% of areas have the hierarchical Bayesian unit-level model with lower variance than the unit-level EBLUP. In the case of this thesis, significant variance gains by implementing the unit-level hierarchical Bayesian estimator are not made; however, there are benefits of the implementation of this estimator. First, this piece of this thesis can serve as a case study of a hierarchical Bayesian estimator converging in variance and estimates to the analogous frequentist estimator. This allows for the verification of a statement often made in Bayesian statistics courses and textbooks with a real world example rather than a mathematical proof. Second, the unit-level hierarchical Bayesian estimator is much more flexible than the unit-level EBLUP and it does a very similar job to the unit-level EBLUP. One can "tweak" the behavior of this estimator through the use of priors, or even a different linking model if preferred. These changes could allow for a more successful estimator at the unit-level without changing many processes computationally. If one were to attempt to approach improving the unit-level model starting with the EBLUP, they would be met with restrictions due to the rigidity of the EBLUP's mathematics, and they would have to construct a new estimator entirely.
