```{r, include = F}
library(tidyverse)
library(ggpubr)
library(patchwork)
dat_small <- read_csv("data/subsets/dat_small.csv")

dat_area <- dat_small %>%
  group_by(subsection, section, province) %>%
  summarize(mean_BIOLIVE = mean(BIOLIVE_TPA),
            mean_BALIVE = mean(BALIVE_TPA),
            mean_CNTLIVE = mean(CNTLIVE_TPA),
            mean_VOLNLIVE = mean(VOLNLIVE_TPA),
            var_BIOLIVE = var(BIOLIVE_TPA),
            var_BALIVE = var(BALIVE_TPA),
            var_CNTLIVE = var(CNTLIVE_TPA),
            var_VOLNLIVE = var(VOLNLIVE_TPA),
            mean_nlcd11 = mean(nlcd11),
            var_nlcd11 = var(nlcd11)) 
m333_area <- dat_area %>%
  filter(province == "M333")
m333 <- dat_small %>%
  filter(province == "M333")
load("data/models/unit1.rds")
```

# Results {#results}
## Modeling Overview
We explore both unit- and area-level models in this thesis, where unit-level models fit the model to the plot (unit) level data, and the area-level models fit to data which has been aggregated to the ecosubsection (area) level. These models types each have their own costs and benefits, and while we lose some data structure with the area-level estimates we gain a large amount of precision. We can see this when looking at the correlation between the predictor `nlcd11` and one of our response variables, `BIOLIVE_TPA`, at both the unit- and area-levels with ordinary least squares regression lines fit to the data:

```{r, echo = F, message = F, warning = F, fig.cap="Unit-level correlation", out.width = "90%", fig.align="center"}
ggplot(m333, aes(x = nlcd11,
                      y = BIOLIVE_TPA)) +
  geom_point(alpha = 0.5,
             position = "jitter") +
  stat_cor(color = "steelblue", aes(label = ..rr.label..)) +
  stat_smooth(method = "lm", se = F, color = "steelblue") +
  theme_bw()
```
```{r, echo = F, message = F, warning = F, fig.cap="Area-level correlation", out.width = "90%", fig.align="center"}
ggplot(m333_area, aes(x = mean_nlcd11,
                      y = mean_BIOLIVE)) +
  geom_point() +
  stat_cor(color = "steelblue", aes(label = ..rr.label..)) +
  stat_smooth(method = "lm", se = F, color = "steelblue") +
  theme_bw()
```


Notably, the $R^2$ value for the area-level simple linear regression is much higher than the $R^2$ value at the unit-level. This is of course compromised by the number of data points ($n_{area} = 20, ~ n_{unit} = 3003$). Also, fitting a polynomial regression curve to the unit level data hardly improves the fit ($R^2 = 0.44$). 

We, however, are not fitting simple linear regressions. In this chapter, we explore the benefits of Bayesian hierarchical models which use varying-slopes to lower the variance in our estimates at the cost of a small amount of bias. 

## Unit-level Models

At the unit-level, the small area estimates for each ecosubsection are made by post-aggregation of the plot level output of our model. We fit these models using varying slopes model, which can be written as: 
\begin{align*}
Y_i &\sim N(\alpha_j + \vec\beta\vec X_i,~ \sigma^2) \\
\alpha_j &\sim N(\mu_\alpha,~ \sigma^2_\alpha) \\
\mu_\alpha &\sim N(a,~b)
\end{align*}
Here, we have $Y_i$, our response variable (`BIOLIVE_TPA`), which is modeled to have a Gaussian posterior distribution with mean $\alpha_j + \vec\beta\vec X_i$ which can change intercept based on the level that a given observation is in. Note that we are predicting $Y$ at the unit-level, so we compute $Y_i$ for every plot in the Northern Rocky Forest, and we allow $\alpha_j$, the intercept, to vary over each of the 20 ecosubsections within the Northern Rocky Forest. Then, we must aggregate our result by taking the mean of our $Y_i$'s in each small area. After fitting this model and preforming the aggregation, we can look at the estimates of the mean biomass predicted by the model compared to the direct estimator:

```{r, echo = FALSE, fig.cap="Direct and model-based estimates for the unit-level model", message = F, warning = F, out.width = "90%", fig.align="center"}
mod_df <- data.frame(
  fitted = mod$fitted.values,
  subsection = m333 %>% dplyr::select(subsection),
  true = mod$y
)
sub_mean <- mod_df %>%
  group_by(subsection) %>%
  summarize(mean_y = mean(true))
bayes_cv <- mod_df %>%
  group_by(subsection) %>%
  yardstick::rmse(truth = true,
                  estimate = fitted) %>%
  left_join(sub_mean) %>%
  group_by(subsection) %>%
  summarize(cv = .estimate / mean_y)
mod_df %>%
  group_by(subsection) %>%
  summarize(mean_direct = mean(true),
            mean_bayes = mean(fitted)) %>%
  mutate(subsection = fct_reorder(subsection, mean_direct)) %>%
  ggplot(aes(x = subsection)) +
  geom_point(aes(y = mean_bayes,
                 color = "goldenrod"),
             position = position_nudge(x = -0.1)) + 
  geom_point(aes(y = mean_direct,
                 color = "forestgreen"),
             position = position_nudge(x = 0.1)) +
  theme_bw() +
  scale_color_manual(
    name = 'Estimate Type',
    values = c('goldenrod' = 'goldenrod',
               'forestgreen' = 'forestgreen'),
    labels = c('Direct (Mean)', 'Hierarchical Bayesian'),
    guide = "legend"
  ) +
  theme(axis.text.x = element_text(
    angle = 90,
    vjust = 0.5,
    hjust = 1
  ),
  legend.position = "bottom") +
  labs(x = "Subsection",
       y = "Estimate")
```
These estimates make sense in the context of hierarhical Bayesian modeling because we can see the shrinkage of the estimates towards the overall mean. We also see more shrinkage in ecosubsections which have less plots, particularly M333Cc ($n_j = 28$), M333Ai ($n_j = 38$), and M333Ad ($n_j = 26$). This is again consistent with our intuition as small areas with less data should rely more heavily on the overall mean biomass level of the Northern Rocky Forest. 

We can also begin to look at the increase in precision which is gained from this unit-level hierarchial Bayesian model by examining the coefficient of variation for the model and the direct estimator in each ecosubsection. For the direct estimator, the coefficient of variation of a certain ecosubsection $j$ is defined as
\begin{align}
CV_{\text{direct}} = \frac{\sqrt{\text{var}(Y_{i,j})}}{\text{mean}(Y_{i,j})}
\end{align}
where $Y_{i,j}$ considers all $i = 1,\dots,n_j$ units in the $j$th ecosubsection. Similarly, for the model-based estimator we define the coefficient of variation as
\begin{align}
CV_{\text{model}} = \frac{\sqrt{\frac{1}{n}\sum_{i=1}^{n_j} (Y_{i,j} - \hat{Y}_{i,j})^2}}{\text{mean}(Y_{i,j})}
\end{align}
Note that the numerator is now the root mean squared error of the $j$th ecosubsection. This is equvalent to taking the square root of the variance as we did in the direct estimator's coefficent of variation, given that our model perfectly meets our modeling assumptions. Knowing that this will never perfectly be the case, we take the root mean squared error to get a more realistic estimate. Now, we can visualize this statisitc for each ecosubsection:

```{r, message = F, warning = F, echo = F, fig.cap = "Direct and model-based coefficients of variation for the unit-level model", out.width = "90%", fig.align="center"}
mod_df %>%
  group_by(subsection) %>%
  summarize(direct_cv = sd(true) / mean(true)) %>%
  left_join(bayes_cv) %>%
  mutate(subsection = fct_reorder(subsection, direct_cv)) %>%
  ggplot(aes(x = subsection)) +
  geom_point(aes(y = cv, color = "goldenrod")) +
  geom_point(aes(y = direct_cv, color = "forestgreen")) +
  theme_bw() +
  scale_color_manual(
    name = 'Estimate Type',
    values = c('goldenrod' = 'goldenrod',
               'forestgreen' = 'forestgreen'),
    labels = c('Direct (Mean)', 'Hierarchical Bayesian'),
    guide = "legend"
  ) +
  theme(axis.text.x = element_text(
    angle = 90,
    vjust = 0.5,
    hjust = 1
  ),
  legend.position = "bottom") +
  labs(x = "Subsection",
       y = "Coeffcient of Variation")
```
```{r, include = F, echo = F, warning = F, message=F}
mean_prop <- mod_df %>%
  group_by(subsection) %>%
  summarize(direct_cv = sd(true) / mean(true)) %>%
  left_join(bayes_cv) %>%
  mutate(prop = (cv / direct_cv)) %>%
  summarize(mean = mean(prop)) %>% pull()

bayes_cv_overall <- mod_df %>%
  yardstick::rmse(truth = true,
                  estimate = fitted) %>%
  summarize(cv = .estimate / mean(mod_df$true, na.rm = T)) %>%
  pull()

```
We see reductions in every coefficient of variation from the direct estimator to our model-based approach, with an average reduction in of `r round(100*(1 - mean_prop), 2)`%. However, the variation we see is still much larger than wanted, with the ecosubsection with the lowest coefficent of variation just over 0.6 and the overall coefficient of variation of the model at a value of `r round(bayes_cv_overall, 2)`. These large coefficients of variation indicate that even though we were able to reduce the variance in the estimate by an average of `r round(100*(1 - mean_prop), 2)`%, the will not perform well enough to be used as a reliable predictor of average biomass. 

