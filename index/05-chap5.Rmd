```{r, include = F}
library(tidyverse)
library(ggpubr)
library(patchwork)
library(sf)
library(USAboundaries)
res <- readRDS("data/results/final_results.rds")
res_long <- readRDS("data/results/final_results_long.rds")
dat <- read_csv("data/subsets/dat_small.csv") %>%
  filter(province %in% unique(res_long$province))
```

# Results {#results}

This chapter addresses the performance of the six estimators fit in this thesis: the sample mean, the post-stratified estimator, the unit-level EBLUP, the area-level EBLUP, the unit-level hierarchical Bayesian estimator, and the area-level hierarchical Bayesian estimator. 

We used the R statistical software to compute our results [@r-software]. The sample mean was computed using the *sae* [@sae-package]. The post-stratified estimates were computed using *mase* [@mase]. The frequentist EBLUP estimates were computed using *sae* [@sae-package]. The hierarchical Bayesian estimates were computed using *hbsae* [@hbsae-package]. The results were tidied, processed, and visualized using many *tidyverse* packages [@tidyverse]. Our data spans the entire Interior West, however we were forced to exclude a few eco-provinces. Namely two eco-provinces with a very small number of eco-subsections which caused errors in producing the unit-level hierarchical Bayesian estimates and eco-subsections with either none or very close to no sampled areas with non-zero values for our variables of interest. While this is disappointing, we still were able to fit these estimators to the great majority of our data. 

This thesis uses all six of these estimators to produce estimates for basal area (square-foot), tree count per acre, above-ground biomass (lbs), and net volume ($\text{ft}^3$). The EBLUP and hierarchical Bayesian estimators use one explanatory variable, total canopy cover, to produce estimates. Our estimation occurs at the eco-subsection level, and thus we have 10,176 estimates produced (six estimators, four response variables, and 424 eco-subsections). 

We are generally concerned with producing estimates that have both low variance and low bias. So, this chapter primarily aims to answers questions regarding these two quantities. In order to do so, we will summarize our findings both globally and by briefly examining a subset of our results in the Northern Rocky Forest. This subset examination allows us to dig in to results without much aggregation or overwhelming plots due to the large amount of results we have. We explore both metrics and visualizations of variance and bias across the interior west in order to deeply understand the performance of our estimators. This thesis is, in many ways, a study navigating the bias-variance trade-off in depth in a real world setting. While quantifying variance of estimates is a generally straight forward task, producing an accurate depiction of bias is extremely difficult without knowing population parameters. 


## Estimator Performance

We will now investigate the performance of the six estimators used in this thesis. In order to explore variance, the primary metric we use is the coefficient of variation ($CV$). This metric, for each estimator, is defined as the standard deviation of our estimate divided by the sample mean in that small area ($\hat \mu_{y_j}^{HT}$). This allows us to normalize our variation across different response variables and areas that are more or less forested. We can express the coefficient of variation as follows:
\begin{align}
CV_{y_j} = \frac{\hat\sigma_{y_j}}{\hat\mu_{y_j}^{HT}}
\end{align}
It is notable that when the mean of the variable of interest is small, we will sometimes get strangely large coefficients of variation for estimators that borrow strength. This phenomenon can generally be thought of as more to do with intrinsic (and often very good) qualities of the estimator rather than the correlating with poor performance of the estimator when the sample mean is small. Notably, estimators which borrow strength to a large degree in situations where the sample mean is low and the areas which we borrow strength from have significantly higher values will have higher variance due to this heterogeneity. We will explore this idea in depth further on in this chapter. 

In order to visualize the coefficients of variation in an appealing way, we have filtered all observations greater than one in the following plot:  

```{r cov-violin, fig.align="center", out.width='100%', echo = FALSE, warning = F, message = F, fig.scap="Distribution of the coefficient of variation of each eastimator", fig.cap = "Distribution of the coefficient of variation of each eastimator. The black dot in each violin segment represents the median coefficient of variation value. The width of the violin segments corresponds to the density of points in the given value range. Values greater than 1 truncated in plot, however still considered in median calculation."}
med <- res_long %>%
  group_by(estimator) %>%
  summarize(median_cov = median(cov))

res_long %>%
  ggplot(mapping = aes(x = estimator,
                       y = cov,
                       fill = estimator)) +
  geom_violin(alpha = 0.5) +
  stat_summary(fun.y="median", geom="point") +
  ylim(0,1) +
  theme_bw() +
  scale_fill_manual(values = c("#A9A9A9", "#334F44", "#E7AB26",
                               "#BF4C27",  "steelblue",  "#80BCA2"),
                    labels = c("Sample Mean", "Post-Stratification", "Area EBLUP",
                               "Unit EBLUP", "Area HB", "Unit HB")) +
  scale_x_discrete(labels = c("Sample Mean", "Post-Stratification", "Area EBLUP",
                               "Unit EBLUP", "Area HB", "Unit HB")) +
  theme(legend.position = "bottom") +
  labs(title = "Coefficient of Variation of Each Estimator",
       x = "Estimator",
       y = "Coefficient of Variation",
       fill = "Estimator")
```
Figure \@ref(fig:cov-violin) shows the coefficient of variation for each estimator. We see a slight reduction in the coefficient of variation when moving from the sample mean to post-stratification, and a decently large reduction in variation when adding auxiliary data with either EBLUP estimator. We also see that the unit-level hierarchical Bayesian estimator performs quite similarly to the unit-level EBLUP. This makes sense as at the unit-level we have so much data that it outweighs the contribution of any priors significantly. Finally, we see a huge reduction in the coefficient of variation compared to all other estimators when we fit the area-level hierarchical Bayesian estimator. The median coefficient of variation for this area-level hierarchical Bayesian estimator (`r round(med$median_cov[5], 3)`) is less than half of the next best performing median coefficient of variation from the area-level EBLUP (`r round(med$median_cov[3], 3)`). Examining the 25%, 50%, and 75% quantile of these estimator's coefficient of variation continues to show the superiority of the area-level hierarchical Bayesian estimator:
```{r quantile-table, echo = F}
quantiledf <- bind_rows(
  quantile(res$cov_dirmean)[2:4],
  quantile(res$cov_dirps)[2:4],
  quantile(res$cov_freq_area)[2:4],
  quantile(res$cov_freq_unit)[2:4],
  quantile(res$cov_hb_area)[2:4],
  quantile(res$cov_hb_unit)[2:4],
  ) %>%
  mutate(Estimator = c("Sample Mean", "Post-Stratification", "Area EBLUP",
                       "Unit EBLUP", "Area HB", "Unit HB")) %>%
  relocate(Estimator)

knitr::kable(
  quantiledf,
  digits = 3,
  caption = "25th, 50th, and 75th Quantile of Each Estimator's Coefficient of Variation",
  caption.short = "Coefficient of Variation Quantiles",
  longtable = TRUE,
  booktabs = TRUE
)
```

While Figure \@ref(fig:cov-violin) and Table \@ref(tab:quantile-table) gives us a good sense of the distribution, we must acknowledge that we truncated some values in order for viewing simplicity. By examining the distribution and performance of the coefficients of variation by truncating the tails we can gain insight that would be much harder to see while including the tails. Now, we can look at the tails of these distributions. Four estimators had coefficients of variation that exceeded 1. The below table shows the count and proportion of each:
```{r over-one, echo = FALSE, warning = F, message = F}
over_one <- res_long %>%
  filter(cov > 1) %>%
  group_by(estimator) %>%
  summarize(Count = n(),
            Proportion = Count / (length(res_long$response) / length(unique(res_long$estimator)))) %>%
  rename(Estimator = estimator) %>%
  mutate(Estimator = case_when(Estimator == "freq_unit" ~ "Unit EBLUP",
                               Estimator == "hb_area" ~ "Area HB",
                               Estimator == "hb_unit" ~ "Unit HB",
                               Estimator == "dirmean" ~ "Sample Mean")) %>%
  bind_rows(data.frame(Estimator = c("Post-Stratification", "Area EBLUP"),
                       Count = c(0,0),
                       Proportion = c(0.000, 0.000))) %>%
  arrange(Count)

knitr::kable(
  over_one,
  digits = 3,
  caption = "Coefficient of variation estimates greater than one",
  longtable = TRUE,
  booktabs = TRUE
)
```
We see that there are three estimators with over 1% of their coefficient of variations greater than one. Both the frequentist and hierarchical Bayesian unit-level estimators have many values greater than one, and the area-level hierarchical Bayesian has some as well. To understand why these particular estimators have many estimates greater than one, we first need to explore the small areas which have these coefficient of variation values. To do so, we can examine the mean response value for estimates where the coefficient of variation is greater than one and when it is less than one. 
```{r covg1l1, message = F, warning = F, echo = F}
cov_g_1 <- res_long %>%
  mutate(`CV > 1` = cov > 1) %>%
  group_by(response, `CV > 1`) %>%
  summarize(mean = mean(estimate)) %>%
  pivot_wider(values_from = mean, names_from = `CV > 1`) %>%
  rename(l1 = `FALSE`,
         `g1` = `TRUE`)
names(cov_g_1) <- c("Response", "Mean Estimate (CV < 1)", "Mean Estimate (CV > 1)")

knitr::kable(
  cov_g_1,
  digits = 3,
  caption = "Mean Estimates Where Coefficent of Variation is Greater Than and Less Than One",
  longtable = TRUE,
  booktabs = TRUE
)
```
From this table we are able to confirm that we see high coefficients of variation more often in areas with lower values for our response variable. It now becomes apparent why some estimators have many coefficients of variation greater than one and others have none or very few. The three estimators which have a significant number of estimates associated with a coefficient of variation greater than one (unit-level hierarchical Bayesian and frequentist, area-level hierarchical Bayesian) all will borrow a great deal of strength from outside eco-subsections when those outside eco-subections have a much higher response variable value than the eco-subsection of interest. In other words, with these three estimators, eco-subsections with lower response variable values will get larger estimates. These larger estimates require larger standard errors as we are unsure whether we had a non-representative sample (too low) in the given eco-subsection or if this eco-subsection truly has a low value for its response variable(s). However when we are choosing methods of estimation which borrow strength, this is a property we like to see. In fact, estimators which do not borrow strength in these situations and have small coefficients of variation will often produce under-estimates with an artificial amount of precision. We can see this phenomenon below by examining the performance of the hierarchical Bayesian area-level estimator compared to the post-stratified estimator: 

```{r fig.align="center", out.width='100%', echo = FALSE, warning = F, message = F,}
means <- res_long %>%
  filter(estimator == "dirmean") %>%
  rename(mean = estimate) %>%
  dplyr::select(subsection, response, mean)
res_long <- res_long %>%
  full_join(means, by = c("subsection" = "subsection",
                          "response" = "response"))
res_long <- res_long %>%
  mutate(se = mean * cov)

res_long %>%
  filter(province == "M333",
         response == "BALIVE_TPA") %>%
  mutate(subsection = str_sub(subsection, 5),
         subsection = fct_reorder(subsection, estimate)) %>%
  filter(estimator %in% c("dirps", "hb_area")) %>%
  ggplot(mapping = aes(x = subsection,
                       y = estimate,
                       color = estimator)) +
  geom_point() +
  geom_errorbar(aes(ymin = estimate - se, ymax = estimate + se)) +
  scale_color_manual(values = c("#334F44", "steelblue"),
                     labels = c("Post-Stratification", "Area HB")) +
  theme_bw() +
  theme(legend.position = "bottom")
```

The frequentist area-level estimator has a different approach to making these estimates. Notably, in the case of small within-area variation we see that the EBLUP will put a heavy weight on the post-stratified estimate from Equation \@ref(eq:eblup-area-weight). We can see this occur by comparing the area-level frequentist estimator to the post-stratified estimate with the same eco-province and response variable as above: 
```{r fig.align="center", out.width='100%', echo = FALSE, warning = F, message = F,}
res_long %>%
  filter(province == "M333",
         response == "BALIVE_TPA") %>%
  mutate(subsection = str_sub(subsection, 5),
         subsection = fct_reorder(subsection, estimate)) %>%
  filter(estimator %in% c("dirps", "freq_area")) %>%
  ggplot(mapping = aes(x = subsection,
                       y = estimate,
                       color = estimator)) +
  geom_point() +
  geom_errorbar(aes(ymin = estimate - se, ymax = estimate + se)) +
  scale_color_manual(values = c("#334F44", "#E7AB26"),
                     labels = c("Post-Stratification", "Area EBLUP")) +
  theme_bw() +
  theme(legend.position = "bottom")
```
Overall, we can see that the frequentist area-level estimator performs much more similarly to the post-stratified estimator, a trait that may or may not be appealing based on the confidence we have in representative sampling. In an attempt to quantify the magnitude of difference between two estimators we introduce percent relative difference, which we define below.
\begin{align*}
PRD(\hat\mu_1,~ \hat\mu_2) = \frac{\hat \mu_1 - \hat\mu_2}{\hat\mu_2} \cdot 100
\end{align*}
While we could explore percent relative difference between all combinations of estimators, the Forest Inventory and Analysis Program's go-to estimator is post-stratification, so we will compare the remaining five estimators to post-stratification. Below, we can see the quantiles of percent relative difference to post-stratification.
```{r, echo = F, warning = F, message = F}
knitr::kable(
  bind_rows(
    quantile((res$est_hb_unit - res$est_dirps) / (res$est_dirps)) * 100,
    quantile((res$est_hb_area - res$est_dirps) / (res$est_dirps)) * 100,
    quantile((res$est_freq_unit - res$est_dirps) / (res$est_dirps)) * 100,
    quantile((res$est_freq_area - res$est_dirps) / (res$est_dirps)) * 100
  ) %>%
    mutate(Estimator = c("Unit HB", "Area HB", "Unit EBLUP", "Area EBLUP")) %>%
    relocate(Estimator),
  digits = 3,
  caption = "Quantiles of Percent Relative Difference to the Post-Stratified Estimator",
  longtable = TRUE,
  booktabs = TRUE)
```



```{r, warning = F, message = F, echo = F, include = F}
subsections <- st_read("../data/SA_eco_subsection/SA_eco_subsection.shp", quiet = TRUE)

interior_west <- c("AZ", "CO", "ID", "MT", "NV", "NM", "UT", "WY")

int_west_sf <- us_boundaries(type = "state",
                         states = interior_west)

modeled_subsections <- st_intersection(int_west_sf, subsections) %>%
  dplyr::select(PROVINC, SECTION, SUBSECT, geometry)

res_sf <- res %>%
  full_join(modeled_subsections, by = c("subsection" = "SUBSECT")) %>%
  distinct()

ggplot() +
  geom_sf(data = res_sf,
          mapping = aes(fill = log(cov_hb_area),
                        geometry = geometry),
          color = "black") +
  theme_void() 

ggplot() +
  geom_sf(data = res_sf,
          mapping = aes(fill = log(est_hb_area),
                        geometry = geometry),
          color = "black") +
  theme_void() 
```


The Northern Rocky Forest is a large eco-province spanning many states, and can be seen in Figure \@ref(fig:northern-rocky). 

```{r m333-cov, echo = F, warning = F, message = F, include = F}
res_long %>%
  filter(province == "M333",
         response == "BALIVE_TPA") %>%
  mutate(subsection = str_sub(subsection, 5)) %>%
  ggplot(mapping = aes(x = subsection,
                       y = cov,
                       color = estimator)) +
  geom_point() +
  scale_color_manual(values = c("#A9A9A9", "#334F44", "#E7AB26",
                                "#BF4C27",  "steelblue",  "#80BCA2"),
                     labels = c("Sample Mean", "Post-Stratification", "Area EBLUP",
                                "Unit EBLUP", "Area HB", "Unit HB")) +
  theme_bw() +
  theme(legend.position = "bottom")

res_long %>%
  filter(province == "M333",
         response == "BALIVE_TPA") %>%
  mutate(subsection = str_sub(subsection, 5)) %>%
  ggplot(mapping = aes(x = subsection,
                       y = estimate,
                       color = estimator)) +
  geom_point() +
  scale_color_manual(values = c("#A9A9A9", "#334F44", "#E7AB26",
                                "#BF4C27",  "steelblue",  "#80BCA2"),
                     labels = c("Sample Mean", "Post-Stratification", "Area EBLUP",
                                "Unit EBLUP", "Area HB", "Unit HB")) +
  theme_bw() +
  theme(legend.position = "bottom")
```



