# Methods {#methods}

<!-- Gives an overview of the current main approaches to the problem. -->
<!-- Points out flaws in existing approaches and addresses how the current work mitigates these problems -->

Currently, there are three main types of estimators used to estimate the value of forest attributes: direct, indirect with implicit models, and indirect with explicit models. Direct estimators are commonly thought of as the simplest estimators as they do not borrow strength across small areas for estimation. Direct estimators are hence easy to use and interpret, but we often do not get precise enough estimates with these estimators, in other words, they have high variance. Indirect estimators with implicit models borrow strength implicitly across small areas to produce estimates. These estimators decrease variance by providing a link to related small areas through supplementary data [@rao2014]. Finally, indirect estimators that make explicit use of a model, or "model-based estimators", aim to reduce variance in estimates by using auxiliary data and making specific allowance for between area variation. As explained in Rao (2014), these model-based estimators have significant advantages over direct estimators and implicit indirect estimators. Notably, model diagnostics can be used, small area-specific measures of precision can be attained (in our case, we compare the coefficient of variation between estimators), and we can used mixed or hierarchical models to capture the dependence structure in the data. 

This thesis explores the application of two model-based estimators, the hierarchical Bayesian unit-level model and the hierarchical Bayesian area-level model. These hierarchical Bayesian models are not commonly used in forest inventory research, however these models are often applied in a variety of other application areas ranging from ophthalmology to economic growth to tracking the spread of invasive species, to name a few [@med; @inbook; @doves]. We compare these novel Bayesian models to the frequentist EBLUP unit- and area-level models and two common direct estimators, the sample mean and the post-stratified estimator. To compare these estimators, we will apply them over many ecological provinces in the Interior West and study their performance when considering four key response variables with one explanatory variable. 

In order to explore these estimators in depth, we must introduce notation relevant to them. First of all, our indices will work as follows: $i$ indexes over units sampled; $j$ indexes over eco-subsections or "small areas"; and $k$ indexes over strata. Now, we are interested in estimating the mean of some response variable $y$, such as trees per acre or biomass, in a small area. So, let $\mu_{y_j}$ be the population mean of the study variable in eco-subsection $j$ in the Interior West. To denote the estimate produced of $\mu_{y_j}$ we will use $\hat\mu_{y_j}$ with a superscript denoting which estimator is being used. We will also use $V(\hat\mu_{y_j})$ to denote the variance of $\hat\mu_{y_j}$. In summary, each of our estimators aims to estimate $\mu_{y_j}$, the population mean of some study variable in the $j$th eco-subsection and our estimated value is denoted by $\hat\mu_{y_j}$ and its variance is denoted by $V(\hat\mu_{y_j})$. We also must introduce $s_j$, which is a set. The set $s_j$ includes all units sampled within eco-subsection $j$. We also introduce $U_j$, the set of all the area in subsection $j$. The "$U$" is chosen as it stands for "universe." Also, we introduce $n_j$, this denotes the number of sampled units within an eco-subsection $j$, i.e. the cardinality of $s_j$. 


## Direct Estimation

There are two direct estimators that we implement throughout this thesis: the sample mean (a.k.a. the Horvitz-Thompson estimator) and the post-stratified estimator. While the sample mean is an intuitive choice for estimating the population mean of a variable of interest $y$, the post-stratified estimator helps correct for over- and under-sampling of forested areas. We also introduce a direct estimator which helps create intuition for the unit-level frequentist model, however we do not fit this model to our data. We will now explore the mathematics behind these estimators in depth. 

### The Horvitz-Thompson Estimator

What might be the most intuitive approach to estimating the population mean $\mu_{y_j}$ is taking the sample mean, i.e. using the "Horvitz-Thompson estimator" as survey samplers like to say [@hor52]. This estimator can be expressed as follows:
\begin{align}
\hat\mu_{y_j}^{HT} = \frac{1}{n_j} \sum_{i \in s_j} y_i
\end{align}
Ignoring the finite population correction, the variance estimate for Horvitz-Thompson estimator is calculated by:
\begin{align}
\hat V\Big(\hat\mu_{y_j}^{HT}\Big) = \frac{1}{n_j-1} \sum_{i \in s_j} \Big(y_{ij} - \hat\mu_{y_j}^{HT}\Big)^2
\end{align}
Recall that the Horvitz-Thompson estimator is just taking the mean of the study variable of interest, $y$. Note that $y_i$ represents the value of the study variable in the $i$th unit sampled of eco-subsection $j$. This estimator is useful as it is easy to compute and does not require any auxiliary information. However, the Horvitz-Thompson estimator high variance relative to other estimators we will discuss. The post-stratified estimator begins to address the variance of the Horvitz-Thompson estimator.

### The Post-Stratified Estimator

The post-stratified estimator is very similar to the Horvitz-Thompson estimator however, as stated above, it addresses variance that occurred from using the Horvitz-Thompson estimator. While decreasing variance seems like a no cost solution to some of our problems, the post-stratified estimator requires auxiliary information in order to be used. The post-stratified estimator is a weighted sum of two Horvitz-Thompson estimators: one Horvitz-Thompson estimator giving the estimate of the mean in sampled units which are forested and the other Horvitz-Thompson estimator in non-forested areas. We then weight these estimates by the true proportion of area in the eco-subsection of interest that is forested. Note that while we are using auxiliary information such as the true proportion of forested area in the eco-subsection of interest and whether or not the sampled units were forested areas or not, both of these pieces of information only consider the eco-subsection of interest. Therefore, since information is not used from outside of the eco-subsection of interest, the post-stratified estimator is still within the family of direct estimators. We can represent the post-stratified estimator as follows:
\begin{align}
\hat\mu_{y_j}^{PS} = \sum_{k=1}^{2} w_{jk} \cdot \hat\mu_{y_{jk}}^{HT}
\end{align}
Ignoring the finite population correction, the variance estimate for post-stratified estimator is calculated by:
$$
\hat V\Big(\hat \mu_{y_j}^{PS}\Big) = 
\frac{1}{n_j} \Bigg( \sum_{k=1}^{2} w_{jk} n_{jk} \hat V\Big(\hat\mu_{y_{jk}}^{HT}\Big) + 
\sum_{k=1}^{2} (1 - w_{jk}) \frac{n_{jk}}{n_j} \hat V\Big(\hat\mu_{y_{jk}}^{HT}\Big) \Bigg)
$$
Recall that $k$ indexes over our strata, which in this case is forested and non-forested sampled units. We also have $w_k$, which is a survey weight entirely decided by the true proportion of eco-subsection $j$ which is forested. For example, if eco-subsection $j$ was 80% forested, we would have $w_1 = 0.8$ and $w_2 = 0.2$. Therefore if we had under-sampled forests at only 60% of our samples, we correct this under-sampling with our survey weights and this results in a better estimate of $\mu_{y_j}$ that is less variable. 

The post-stratified estimator is a great alternative to the Horvitz-Thompson estimator when auxiliary information related to the response variable of interest is available, and in that situation there is not a justifiable reason to pick the Horvitz-Thompson estimator over the post-stratified estimator as the direct estimator of choice. We have access to the information needed to compute the post-stratified estimate in the Interior West so we will primarily be comparing our indirect estimators to the post-stratified estimator in our results. Also, our area-level indirect model-based estimators will be based on the post-stratified estimate. 

### The Survey Regression Estimator

Another direct estimator that is often used for small area estimation is the survey regression estimator. While we do not implement in this estimator, the unit-level frequentist EBLUP estimator can be written as a weighted average of the survey regression estimator and a regression-synthetic estimator. Thus, it is important to understand the intuition behind this estimator in order to fully understand how the unit-level frequentist EBLUP estimator works. We can represent the survey regression estimator as follows:
\begin{align}
\hat \mu_{y_j}^{SR} = \frac{1}{N_j} \sum_{i \in U_j} \hat y_{ji} +
\frac{1}{n_j} \sum_{i \in s_j} (y_{ji} - \hat y_{ji})
\end{align}
where $N_j$ is the population size in the $j$th area. The survey regression estimator has a particular subtlety which makes it arguably not a direct estimator. Particularly, the $\hat y_{j,i}$ is calculated through linear regression with $\beta$'s fit by ordinary least squares across the study region, rather than the small area. This is the case for this particular survey regression estimator, as it is the estimator which we can partially represent the unit-level EBLUP estimator by. One may make a quite legitimate argument that this estimator then should in fact be considered an implicit model-based estimator, however Rao (2014) sticks to the convention that this estimator is in fact still a direct estimator. He argues that we should consider this estimator to be a direct estimator as the strength we are borrowing does not increase the "effective" sample size. Making a final decision on this estimator's class is left as an exercise to the reader.  

## Implicit Model-Based Indirect Estimation

Often times it is the case that direct estimation techniques do not provide sufficiently small standard errors to be able to make informative inferences at the small area level. That is the case in our situation, as the FIA's survey design was based around making inferences at larger levels than eco-subsections. One relatively simple approach to decreasing variance of estimates at a small area level is to use auxiliary data from surrounding areas to help attain the estimate in the small area of interest. This process is called borrowing strength. It is very similar to the borrowing of strength outlined in Figures \@ref(fig:hbu-diagram) and \@ref(fig:hba-diagram), however, in the case of implicit model-based indirect estimation we do not allow for between-area variation of explanatory variables. That is, we may borrow strength across small areas by using auxiliary data, but this auxiliary data must be aggregated and have the same effect on each small area within a designated area (in our case, this is the ecological province). 

We introduce two implicit model-based indirect estimators commonly used when auxiliary data is available at the unit- and area-levels. These estimators are not used in the final analyses done in this thesis. However, they are crucial building blocks for understanding the frequentist EBLUP models we discuss and implement. We discuss the regression-synthetic estimator used when area-level auxiliary data is available and then the regression-synthetic estimator used for unit-level auxiliary data.

### The Area-level Regression-Synthetic Estimator

A common method of an implicit model-based indirect estimator outlined by Rao (2014) for area-level is the regression-synthetic estimator. Here, in order to estimate our parameter of interest, $\mu_{y_j}$, we fit an ordinary least squares linear regression on our auxiliary variable. Notably, we use $\bar X_j$ to denote the auxiliary data population mean in the $j$th small area. 
\begin{align}
\hat\mu_{y_j}^{RSA} = \hat\beta_0 + \hat\beta_1 \bar X_{j}
\end{align}
We note that the $\hat \beta$'s are calculated through standard methods of ordinary least squares. Further, it is important to recognize that in the case of the regression-synthetic estimator each small area receives the same $\hat\beta$'s as they are calculated by fitting an ordinary least squares model over all small areas within their eco-province. This is the realization of the requirement that the auxiliary information must have the same effect on each small area. It is also important to note that this estimator can be generalized to $p$ predictors, however in this thesis we use $p=1$.

### The Unit-level Regression-Synthetic Estimator

The unit-level regression-synthetic estimator is very similar to the area-level regression-synthetic estimator. Rather than the ordinary least squares model being fit at the area-level, it is fit at the unit-level. We first fit this unit-level model:
$$
\hat y_{ji} = \hat\beta_0 + \hat\beta_1 X_{ji}
$$
Note that we use capital $X$ to denote the population mean of our explanatory variable at the unit-level. We can do express the unit-level regression-synthetic estimator below:
\begin{align}
\hat\mu_{y_j}^{RSU} = \frac{1}{n_j} \sum_{i \in s_j} \hat y_{ji}
\end{align}
This estimator is very similar to the area-level regression-synthetic estimator as it fits an ordinarily least squares model over the eco-province our small area is in, and the auxiliary information has the same effect on each small area. 

## Explicit Model-Based Indirect Estimation

Often times, implicit model-based indirect estimators still do not reduce variance enough to give us estimates with a reasonably low variance. However, we can turn to explicit model-based indirect estimation in order to combat this issue further. Explicit model-based indirect estimators are extremely useful when relevant auxiliary data is available and we would like to allow for between-area variation of these auxiliary variables. By allowing for this between-area variation our models should fit to the data better given that there is truly between-area variation in the population. In the case of forests across a large portion of the United States, this assumption is very reasonable and one could attribute this variation to a number of factors such as temperature, humidity, or even elevation. Rather than attempting the daunting and nonsensical task of collecting data to fully explain this between-area variation, we fit a mixed model. 

In small area estimation it is most common that the mixed model estimator used is one of the EBLUP estimators: either the unit- or area-level variant depending on the resolution of auxiliary data preferred. The EBLUP estimators are unbiased given the modeling assumptions are met, similar to the post-stratified estimator. We will now explore the model specifications of these EBLUP estimators at the unit- and area-level. 

### The Unit-level EBLUP

In the case of the unit-level EBLUP, we first fit a varying-intercepts linear mixed model at the unit-level:
\begin{align}
y_{i,j} = x_{ij} \beta + \nu_j + e_{ij} (\#eq:unit-mod)
\end{align}
where $\beta$ is calculated from data across the eco-province and will stay constant for each eco-subsection. However, $\nu_j$, the "random effect", will be different for each eco-subsection. This random effect helps account for variation between eco-subsections that the auxiliary data does not account for. The random effects $\nu$ and sampling errors $e$ are assumed to be distributed as follows:
$$
 \newcommand\myeq{\stackrel{\mathclap{\normalfont\mbox{s}}}{~}}
\nu_j \stackrel{\text{iid}}{\sim} \text{N}(0,~ \sigma^2_{\nu}), \quad e_{ij} \stackrel{\text{ind}}{\sim}\text{N}(0, k^2_{ij}\sigma^2_e).
$$
Intuitively, we can think of the variance of the random effect, $\sigma^2_\nu$, as the heterogeneity between our small areas $j$ after we account for our fixed effects [@breidenbach2012]. [NEED TO TALK ABOUT WHAT K IS... cant find explanation in Rao]. 
From our mixed model, Rao (2014) derives the unit-level EBLUP estimator fit in the frequentist paradigm as the weighted average of the survey regression estimator and the regression-synthetic estimator:
\begin{align}
\hat \mu_{y_j}^{FRU} = \hat \gamma_j \hat\mu_{y_j}^{SR} + (1 - \hat \gamma_j) \hat\mu_{y_j}^{RSU}
\end{align}
where
\begin{align}
\hat\gamma_j = \frac{\sigma^2_\nu}{(\sigma^2_\nu + \sigma^2_e / a_i)}
\end{align}
This $\hat\gamma_j$ can be broken down into two parts: the numerator and denominator. The numerator measures the between-area variation, and the denominator measures the total variability. Thus, when a large proportion of the overall variation is between-area variation, the unit-level EBLUP will put more weight on the survey regression estimator. 
(say what $a_i$ is from Rao around 7.1.3, 7.1.4)

For this thesis, in order to compute the variance of the unit-level EBLUP estimator we chose to bootstrap. Bootstrapping is the process taking repeated samples of our data with replacement, computing our statistic on that new bootstrap sample, and then repeating this process many times [@bootstrap]. The property of the bootstrap which is useful to us is that it produces good estimates for the variance of our estimator. For our application, we bootstrap within each small area to compute the variance. For each eco-subsection $j$, we sample $n_j$ plots with replacement. Next, we fit the unit-level EBLUP estimator to the bootstrapped eco-subsections and produce our mean estimate on our first bootstrap sample (we denote each bootstrap sample with $b$, so in this case $b=1$). 
$$
\hat\mu_j^{FRU}(b=1)
$$
Next, we repeat this sampling $B$ times, and in our case we choose $B = 500$ to produce 500 estimates:
$$
\hat\mu_j^{FRU}(b), \quad b = 1,\dots,500
$$
Finally, we compute our estimate of the variance:
\begin{align}
\hat V(\hat\mu_j) = \frac{1}{B-1} \sum_{b=1}^{B}\Big(\hat\mu_j(b) - \overline\mu_j^B\Big)
\end{align}
where $\overline\mu_j^B$ denotes the sample mean of the bootstrap estimates of $\mu_j$. 

### The Area-level EBLUP 

We can also fit the EBLUP at the area-level. In order to do this, we fit the following linear mixed model:
\begin{align}
\hat\mu_{j}^{PS} = x_j \beta + \nu_j + e_j (\#eq:area-mod)
\end{align}
where we assume
$$
 \newcommand\myeq{\stackrel{\mathclap{\normalfont\mbox{s}}}{~}}
\nu_j \stackrel{\text{iid}}{\sim} \text{N}(0,~ \sigma^2_{\nu}), \quad e_{j} \stackrel{\text{ind}}{\sim}\text{N}(0, \sigma^2_e).
$$



Next, Rao (2014) derives the commonly expressed form of the EBLUP estimator:


The area-level EBLUP estimator is expressed by Rao (2014) as a weighted average of the direct estimator and the regression-synthetic estimator:
\begin{align}
\hat \mu_j^{FRA} = \hat\gamma_j \hat\mu_j^{PS} + (1 - \hat\gamma_j) \hat\mu_j^{RS} (\#eq:eblup-area-weight)
\end{align}
where
\begin{align}
\hat \gamma_j = \hat \sigma_\nu^2 b_j^2 / (\psi_j + \hat\sigma_\nu^2 b_j^2)
\end{align}

We compute the variance of this estimator by using the MSE of this estimator. The MSE is expressed by the following equation [@mse-area]:
\begin{align}
V(\hat\mu_j^{FRA}) = MSE(\hat\mu_j^{FRA}) = g_{1j} + g_{2j} + 2g_{3j}
\end{align}
where
\begin{align*}
g_{1j} = \hat\gamma_j \sigma^2_e, \\
g_{2j} = \text{figure this out... wls beta?} \\
g_{3j} = (\sigma^2_e)^2 \cdot (\sigma^2_\nu + \sigma^2_e)^{-3} \cdot 2(\sum_{j} (\sigma^2_\nu + \sigma^2_e)^{-2})^{-1}
\end{align*}

(I need to define a lot of these quantities. Trying to find the best way to do this without pulling every little thing from Rao)

## A Hierarchical Bayesian Approach

So far in this chapter, we have explored common frequentist approaches to small area estimation. However, the research goal of this thesis is to study the performance of the hierarchical Bayesian model for small area estimation. With a hierarchical Bayesian model, we derive the posterior distribution of our variable of interest with either Markov Chain Monte Carlo (MCMC) methods or through numerical integration. We do this by considering both the data (likelihood) and prior distributions. This allows us to use Bayes' Theorem in order to attain our posterior.

Before introducing a slew of notation regarding Bayesian statistics, let's take a step back to recall the type of questions we have been asking so far. Each estimator in this chapter so far has attempted to quantify the mean of our response variable $y$ in each eco-subsection $j$, that is estimating $\mu_{y_j}$. The way in which we attain our estimate $\hat\mu_{y_j}$ and its variance $V\Big(\hat\mu_{y_j}\Big)$ is by asking the question: what sort of $\hat\mu_{y_j}$ would we expect to get under hypothetical resampling? This question is the basis of the name "frequentist" as our estimates in this frequentist paradigm rely on the hypothetical repeated (frequent) sampling. When we choose to use Bayesian methods to estimate $\mu_{y_j}$, we ask a different question: What is our knowledge of $\mu_{y_j}$ based on the data and prior information?

These questions bring up a philosophical difference between Bayesian and frequentist statistics about the addition of prior information. One may object to this, however in this thesis we add very little prior information and rely quite heavily on the data to much of the work for us. Secondly, the addition of prior information allows us to attain a posterior distribution for our estimate of $\mu_{y_j}$, rather than a point estimate. Now with this philosophical difference in mind, recall Bayes' Theorem below:
\begin{align}
P(A ~\vert~ B) &= \frac{P(B ~\vert~ A) \cdot P(A)}{P(B)} \\
&\propto P(B ~\vert~ A) \cdot P(A)
\end{align}
Bayes' Theorem allows us to derive one conditional probability, $P(A ~\vert~ B)$, given that we know the inverse conditional probability and each marginal distribution [@bayes-orig]. This theorem is the basis of our hierarchical Bayesian models. Replacing $A$ with our parameter of interest, $\mu_{y_j}$, and $B$ with our data we get the following equation:
\begin{align}
f(\mu_{y_j} ~\vert~ \text{data}) \propto P(\text{data} ~\vert~ \mu_{y_j}) \cdot P(\mu_{y_j})
(\#eq:bayes-thm)
\end{align}
In our application, we are interested in making inferences about $\mu_{y_j}$ given the data we have. This is represented on the left hand side of Equation \@ref(eq:bayes-thm). We call this quantity the posterior distribution of $\mu_{y_j}$ given the data. As we continue to read left to right, we have our likelihood (or, data) multiplied with the distribution of $\mu_{y_j}$. Clearly we do not know the true value of $\mu_{y_j}$ or else we would not attempt to estimate $\mu_{y_j}$. In order to estimate our posterior distribution we must multiply something with the likelihood function, so we choose a "prior" distribution which reflects our prior belief of the distribution of $\mu_{y_j}$. We can visualize obtaining a posterior distribution below:
```{r, warning = F, message = F, echo = F, fig.cap="Hypothetical prior, likelihood, and posterior distributions. The posterior is inbetween the prior and likelihood as it is the normalized product of these distributions.", fig.scap = "Prior, likelihood, and posterior distributions."}
library(tidyverse)
x <- seq(from = -90, to = 90, by = 1)
data <- dnorm(x, mean = 40, sd = 5)
prior <- dnorm(x, mean = 10, sd = 10)
posterior <- dnorm(x, 25, 4)
bayes_df <- tibble(
  x = rep(x,3),
  distributions = c(prior, data, posterior),
  which_one = c(rep("Prior", 181), rep("Likelihood", 181), rep("Posterior", 181))
)
ggplot(bayes_df, aes(x = x, y = distributions, color = which_one)) +
  geom_line() +
  theme_bw() +
  scale_color_manual(values = c("steelblue", "#BF4C27", "#E7AB26")) +
  theme(legend.position = "bottom",
        axis.ticks = element_blank(),
        axis.text = element_blank()) +
  labs(x = "", y = "", color = "Distribution")
```
Here we can see that our estimate is informed by both the data and the prior distribution, rather than in the frequentist paradigm where only the data is used. We also see that if the prior is "flat", our posterior would just be our likelihood function, leading us to the same result as we achieve through a frequentist analysis, just though a different method. 

These are the concepts and basics of Bayesian statistics applied to the problem at hand: estimating $\mu_{y_j}$. We introduce two methods which estimate $\hat\mu_{y_j}$: the unit-level hierarchical Bayesian estimator and the area-level hierarchical Bayesian estimator. These estimators are analogous to the unit-level EBLUP and the area-level EBLUP, respectively. Notably, when our variance parameters are known and we use flat priors to attain our posterior the hierarchical Bayesian approach and EBLUPs give the same estimates and measures of variability [@rao2014]. However, we of course do not know the underlying parameter values of our variances. We now introduce each estimator. 

### The Unit-level Hierarchical Bayesian Estimator

For the unit-level hierarchical Bayesian estimator, we start with Equation \@ref(eq:unit-mod) as we did for the unit-level frequentist EBLUP. We now just apply a hierarchical Bayesian approach to this equation. We must assume a prior distribution on $\beta$, $\sigma^2_\nu$, and $\sigma^2_e$. We now specify Equation \@ref(eq:unit-mod) as a hierarchical Bayesian model:
\begin{align}
&y_{ij} ~\vert~ \beta,~ \nu_j, \sigma^2_e \sim \text{N}(x_{ij}\beta + \nu_j,~ \sigma^2_e), \nonumber \\
&\nu_j ~\vert~ \sigma^2_\nu \sim \text{N}(0,~ \sigma^2_\nu),\nonumber \\
&f(\beta,~ \sigma^2_\nu, ~\sigma^2_e) = f(\beta)\cdot f(\sigma^2_\nu) \cdot f(\sigma^2_e).
\end{align}
where $f(\beta)$, $f(\sigma^2_\nu)$, and $f(\sigma^2_e)$ are priors specified below:
\begin{align*}
&f(\beta) \propto 1, \\
&\frac{f(\sigma^2_e)}{f(\sigma^2_\nu)} = \text{Inv-Gamma}(\text{df} = 0,~ \text{scale} = 0).
\end{align*}
Now that we have specified the estimator, it is easy to attain the small area estimate and variance. For the estimate, we have:
\begin{align}
\hat\mu_{y_j}^{HBU} = \overline X_j \beta + \nu_j
\end{align}
where $\overline X_j$ is the population mean in the $j$th small area. Finally, for the variance we have:
\begin{align}
V(\hat \mu_{y_j}^{HBU} ~\vert~ \sigma^2_\nu,~ \sigma^2_e) = \text{MSE}(\hat\mu_{y_j}^{HBU}).
\end{align}

### The Area-level Hierarichical Bayesian Estimator

For the area-level hierarchical Bayesian estimator, we start with Equation \@ref(eq:area-mod) as we did for the area-level frequentist EBLUP. We now just apply a hierarchical Bayesian approach to this equation. We must assume a prior distribution on $\beta$ and $\sigma^2_\nu$. We now specify Equation \@ref(eq:area-mod) as a hierarchical Bayesian model:
\begin{align}
&\hat\mu_{y_j}^{PS} ~\vert~ \mu_{y_j},~ \beta,~ \sigma^2_\nu \sim \text{N}(\mu_{y_j},~ \psi_j), \nonumber \\
&\mu_{y_j} ~\vert~ \beta,~ \sigma^2_\nu \sim \text{N}(x_j\beta,~ b_j^2 \sigma^2_\nu),\nonumber \\
&f(\beta,~ \sigma^2_\nu) = f(\beta)\cdot f(\sigma^2_\nu).
\end{align}
where $f(\beta)$ and $f(\sigma^2_\nu)$ and $f(\sigma^2_e)$ are priors specified below:
\begin{align*}
&f(\beta) \propto 1, \\
&f(\sigma^2_\nu) = \text{Inv-Gamma}(\text{df} = 10000 \cdot m,~ \text{scale} = 1).
\end{align*}
where $m$ is the number of small areas in the eco-province we fit the estimator in. Now that we have specified the estimator, it is easy to attain the small area estimate and variance. For the estimate, we have:
\begin{align}
\hat\mu_{y_j}^{HBA} = E[\mu_{y_j} ~\vert~ \hat\mu_{y_j}^{PS}] = 
\end{align}
Finally, for the variance we have:
\begin{align}
V() = 
\end{align}


<!-- Depending on the functional form of the densities we must integrate to obtain our posterior, it is often easier to approximate the distribution with MCMC methods. However, in the case of this thesis, we use numerical integration to extract exact posterior densities from our likelihood and priors. We will now give the form of both the unit- and area-level hierarchical Bayesian models used in this thesis.  -->


<!-- \begin{align} -->
<!-- Y_{i,j} &\sim \text{N}(\nu_j + \vec\beta\vec X_i,~ \sigma^2) \\ -->
<!-- \nu_j &\sim \text{N}(\mu_\nu,~ \sigma^2_\nu) \\ -->
<!-- \mu_\nu &\sim \text{N}(a,~b) \\ -->
<!-- \sigma &\sim \text{Inv-Gamma}(c,~d) -->
<!-- \end{align} -->
<!-- In this model, we have the response variable, $Y$, which is modeled to have a Gaussian posterior distribution with mean $\nu_j + \vec\beta\vec X_i$ which can change intercept based on the level that a given observation is in. Note that $\mu_\nu$ is given a hyperprior distribution where $a$ and $b$ are numbers that often specify a weakly informative or uninformative prior. Often we will set $a=0$ and $b$ equal to some large number to specify a very small amount of prior information. Also, we give the within-area variance a regularizing prior with the Inverse Gamma.  -->


<!-- These are models which are often fit by maximum likelihood estimation and other methods of maximizing the likelihood function such are restricted maximum likelihood estimation. The likelihood can be written as -->
<!-- $$ -->
<!-- P(X ~\vert ~ \theta) -->
<!-- $$ -->
<!-- where $X$ is the data and $\theta$ is the parameter of interest. Note that the likelihood function allows the value of $X$ to vary while the parameter, $\theta$, is considered a fixed value. The other school of statistical thought, Bayesian statistics, considers the parameter of interest as varying while the considering the data as fixed. We call this the posterior distribution of $\theta$, and Bayes' theorem gives us the following relation -->
<!-- $$ -->
<!-- P(\theta ~\vert ~ X) = \frac{P(X ~\vert ~ \theta) P(\theta)}{P(X)} -->
<!-- $$ -->